{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"\ud83d\udde3\ufe0f\ud83d\udc65 Awesome Social Agents <p>For the best experience, we recommend reading this document on the website.</p> <p>The rise of Large Language Models (LLMs)/foundational models presents new opportunities for simulating complex human social behaviors. As a result, there is a rapidly growing body of work emerging in this domain. We hope to categorize and synergize recent efforts to provide a comprehensive guidebook of social agents weaving together multiple domains, including language, embodiment, and robotics. </p> <p>Our goal is to offer insights crucial for understanding and harnessing social agents' potential impact on society. We strive to keep these updated regularly and continuously. We greatly appreciate any contributions via PRs, issues, emails, or other methods.</p> <p>Note</p> <ul> <li>Agent and Environment (Sutton and Barto 2018): An agent is a goal-driven decision-maker that sense and act upon the state of the environment. An environment comprises the state outside the agent, including the other agents if any. </li> <li>Social Agent: An agent that interacts with a multi-agent environment.</li> <li>Socially Intelligent Agent: A social agent that interacts and communicates with other agents in a human-interpretable way. more notes<ol> <li>The social intelligence that we are focusing on is human-like, excluding the collective intelligence in a lot of social animals like ants, bees, fishes. </li> <li>To understand whether an entity is a (social) agent, we have to situate it in an environment. It is not possible to discuss an agent outside of an environment. </li> <li>We acknowledge there are many types of definitions for social agents. Our defitions here help narrow down the scope of our survey.</li> <p>\ud83d\uddc2\ufe0f Check out the examples of social agents. \ud83d\udcda Check out the table format of the collected papers here.</p> <p>\ud83d\udcdd We are currently working on a survey paper related to content of this repository. Stay tuned for updates!</p>"},{"location":"#installation","title":"Installation","text":"<p>This repo supports Python 3.9 and above. In one line, to use a virtual environment, e.g. with anaconda3: </p> <p><code>conda create -n awsome-social-agents python=3.9; conda activate awsome-social-agents; python -m install requirements.txt</code></p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Papers</li> <li>Surveys and Overview</li> <li>Environments<ul> <li>Text and Speech Environments</li> <li>Embodied Environments</li> <li>Virtual Environments</li> <li>Robotics</li> </ul> </li> <li>Modeling<ul> <li>In-context Learning</li> <li>Finetuning</li> <li>Reinforcement learning</li> </ul> </li> <li>Evaluating social agents<ul> <li>Evaluating text social agents</li> <li>Evaluating embodied social agents</li> <li>Evaluating virtual social agents</li> <li>Evaluating robotics in social contexts</li> </ul> </li> <li>Interactions with humans<ul> <li>Human-Chatbot Interaction</li> <li>Human-Embodied Agent Interaction</li> <li>Human Robot Interaction</li> <li>Human-Human Interaction</li> </ul> </li> <li>Challenges<ul> <li>Theory of Mind</li> <li>Social Learning</li> <li>Simultaneous Interaction</li> </ul> </li> <li>Applications<ul> <li>Health</li> <li>Policy</li> <li>Education</li> </ul> </li> <li>Concerns<ul> <li>Risks</li> <li>Safety</li> </ul> </li> </ul>"},{"location":"#papers","title":"Papers","text":""},{"location":"#surveys-and-overview","title":"Surveys and Overview","text":"<p>[June, 2023] Socially intelligent machines that learn from humans and help humans learn, Gweon et al., arXiv</p>"},{"location":"#environments","title":"Environments","text":""},{"location":"#text-and-speech-environments","title":"Text and Speech Environments","text":"<p>[October, 2023] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p>"},{"location":"#embodied-environments","title":"Embodied Environments","text":"<p>[October, 2023] Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots, Puig et al., ICLR</p> <p>[September, 2020] SEAN: Social Environment for Autonomous Navigation, Tsoi et al., HAI</p>"},{"location":"#virtual-environments","title":"Virtual Environments","text":""},{"location":"#robotics","title":"Robotics","text":"<p>[December, 2023] RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments, Haoyu Xiong et al., Proceedings of The 6th Conference on Robot Learning </p> <p>[August, 2022] Do As I Can and Not As I Say: Grounding Language in Robotic Affordances, Michael Ahn et al., arXiv preprint arXiv:2204.01691         </p> <p>[June, 2022] Inner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang et al., arXiv preprint arXiv:2207.05608                    </p> <p>[June, 2023] One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments, Yufei Wang et al., Robotics: Science and Systems (RSS)        </p> <p>[August, 2023] Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration, Chen Wang et al., arXiv                                                 </p> <p>[March, 2024] Yell At Your Robot: Improving On-the-Fly from Language Corrections, Lucy Xiaoyang Shi et al., arXiv                                   </p> <p>[April, 2016] Human--robot interaction: status and challenges, Thomas B Sheridan et al., Human factors             </p> <p>[June, 2021] A taxonomy to structure and analyze human--robot interaction, Linda Onnasch et al., International Journal of Social Robotics         </p> <p>[July, 2023] Robotic vision for human-robot interaction and collaboration: A survey and systematic review, Nicole Robinson et al., ACM Transactions on Human-Robot Interaction         </p> <p>[October, 2022] A survey of multi-agent Human--Robot Interaction systems, Abhinav Dahiya et al., Robotics and Autonomous Systems                                             </p> <p>[March, 2023] Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective, Jacqueline Urakami et al., J. Hum.-Robot Interact.               </p> <p>[April, 2023] 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction, Katie Winkle et al., J. Hum.-Robot Interact.                           </p>"},{"location":"#modeling","title":"Modeling","text":""},{"location":"#in-context-learning","title":"In-context Learning","text":"<p>[May, 2023] Voyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang et al., arXiv</p> <p>[March, 2023] Language Models can Solve Computer Tasks, Geunwoo Kim et al., arXiv                                                                                                                                                               </p> <p>[September, 2024] LASER: LLM Agent with State-Space Exploration for Web Navigation, Kaixin Ma et al., arXiv                                                                                                                                      </p> <p>[May, 2023] Hierarchical Prompting Assists Large Language Model on Web Navigation, Abishek Sridhar et al., arXiv                                                                                                                                </p> <p>[January, 2024] Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control, Longtao Zheng et al., The Twelfth International Conference on Learning Representations                                                    </p> <p>[November, 2023] AdaPlanner: Adaptive Planning from Feedback with Language Models, Haotian Sun et al., Thirty-seventh Conference on Neural Information Processing Systems                                                             </p> <p>[May, 2023] SPRING: Studying the Paper and Reasoning to Play Games, Yue Wu et al., arXiv                                                                                                                                                        </p> <p>[March, 2023] DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents, Varun Nair et al., arXiv                                                                                                                   </p>"},{"location":"#finetuning","title":"Finetuning","text":"<p>[October, 2023] Understanding HTML with Large Language Models, Izzeddin Gur et al., arXiv                                                                                                                                                      [ May, 2023] Instruction-Finetuned Foundation Models for Multimodal Web Navigation, Hiroki Furuta et al., ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models                                          </p> <p>[October, 2023] ReAct: Synergizing Reasoning and Acting in Language Models, Shunyu Yao et al., arXiv                                                                                                                                            </p> <p>[January, 2024] A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis, Izzeddin Gur et al., The Twelfth International Conference on Learning Representations                                         </p> <p>[November, 2023] From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces, Peter Shaw et al., Thirty-seventh Conference on Neural Information Processing Systems                       </p> <p>[January, 2024] GPT-4V(ision) is a Generalist Web Agent, if Grounded, Boyuan Zheng et al., arXiv                                                                                                                                                </p> <p>[February, 2024] Dual-View Visual Contextualization for Web Navigation, Jihyung Kil et al., arXiv           </p>"},{"location":"#reinforcement-learning","title":"Reinforcement learning","text":""},{"location":"#evaluating-social-agents","title":"Evaluating social agents","text":""},{"location":"#evaluating-text-social-agents","title":"Evaluating text social agents","text":"<p>[October, 2024] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p> <p>[March, 2024] RoleInteract: Evaluating the Social Interaction of Role-Playing Agents, Hongzhan Chen et al., arXiv</p> <p>[September, 2023] Approximating Online Human Evaluation of Social Chatbots with Prompting, Svikhnushina et al., Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p> <p>[December, 2023] CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society, Guohao Li et al., Advances in Neural Information Processing Systems</p> <p>[October, 2023] Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay, Yihuai Lan et al., arXiv preprint arXiv:2310.14985</p> <p>[August, 2023] CharacterChat: Learning towards Conversational AI with Personalized Social Support, Quan Tu et al., arXiv</p> <p>[October, 2023] AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems, Junjie Zhang et al., arXiv</p> <p>[March, 2024] How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments, Jen-tse Huang et al., arXiv </p> <p>[August, 2023] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate, Chi-Min Chan et al., arXiv</p> <p>[February, 2024] Automatic Evaluation for Mental Health Counseling using LLMs, Anqi Li et al., arXiv </p> <p>[February, 2024] How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis, Federico Bianchi et al., arXiv</p> <p>[May, 2023] PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits, Hang Jiang et al., NAACL Findings  </p> <p>[February, 2024] Can Large Language Model Agents Simulate Human Trust Behaviors?, Chengxing Xie et al., ArXiv</p> <p>[January, 2024] LLM Harmony: Multi-Agent Communication for Problem Solving, Sumedh Rasal et al., ArXiv</p> <p>[November, 2021] A Comprehensive Assessment of Dialog Evaluation Metrics, Yeh et al., The First Workshop on Evaluations and Assessments of Neural Conversation Systems</p> <p>[July, 2020] {C}onvo{K}it: A Toolkit for the Analysis of Conversations, Chang et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p> <p>[May, 2023] Psychological Metrics for Dialog System Evaluation, Salvatore Giorgi et al., arXiv</p> <p>[May, 2023] ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems, Sarik Ghazarian et al., arXiv</p> <p>[November, 2020] {GRADE}: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems, Huang et al., Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</p> <p>[July, 2020] Unsupervised Evaluation of Interactive Dialog with {D}ialo{GPT}, Mehri et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>"},{"location":"#evaluating-embodied-social-agents","title":"Evaluating embodied social agents","text":"<p>[December, 2022] Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue, Min et al., EMNLP</p> <p>[March, 2024] Embodied LLM Agents Learn to Cooperate in Organized Teams, Xudong Guo et al., arXiv</p> <p>[Februrary, 2021] SocNavBench: A Grounded Simulation Testing Framework for Evaluating Social Navigation Biswas et al., ACM Transactions on Human-Robot Interaction</p> <p>[January, 2021] Evaluating the Robustness of Collaborative Agents Knott et al., AAMAS '21: Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems</p>"},{"location":"#evaluating-virtual-social-agents","title":"Evaluating virtual social agents","text":""},{"location":"#evaluating-robotics-in-social-contexts","title":"Evaluating robotics in social contexts","text":"<p>[March, 2024] HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation, Carmelo Sferrazza et al., arXiv</p> <p>[December, 2020] Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition, Y. Mizuchi et al., Advanced Robotics</p> <p>[July, 2020] Safety bounds in human robot interaction: A survey, Angeliki Zacharaki et al., Safety science</p> <p>[December, 2015] RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots, Luca Iocchi et al., Artificial Intelligence</p> <p>[October, 2011] A meta-analysis of factors affecting trust in human-robot interaction, Peter A Hancock et al., Human factors</p> <p>[November, 2009] Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots, Christoph Bartneck et al., International journal of social robotics</p> <p>[March, 2006] Common metrics for human-robot interaction, Aaron Steinfeld et al., Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction</p> <p>[January, 2003] Theory and evaluation of human robot interactions, J. Scholtz et al., 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the  </p>"},{"location":"#interactions-with-humans","title":"Interactions with humans","text":""},{"location":"#human-chatbot-interaction","title":"Human-Chatbot Interaction","text":"<p>[April, 2023] Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions, Amon Rapp et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p> <p>[March, 2024] AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy, Daniel Pillis et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p> <p>[April, 2023] Exploring effects of chatbot-based social contact on reducing mental illness stigma, Yi-Chieh Lee et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p> <p>[May, 2024] \" It's the only thing I can trust\": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance, JiWoong Jang et al., Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</p> <p>[April, 2022] User perceptions of extraversion in chatbots after repeated use, Sarah Theres V{\\\"o}lkel et al., Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</p> <p>[September, 2022] Interacting with a chatbot-based advising system: Understanding the effect of chatbot personality and user gender on behavior, Mohammad Amin Kuhail et al., Informatics</p> <p>[May, 2023] The Effects of Engaging and Affective Behaviors of Virtual Agents in Group Decision-Making, Hanseob Kim et al., Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</p> <p>[March, 2024] Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration, Crystal Qian et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p>"},{"location":"#human-embodied-agent-interaction","title":"Human-Embodied Agent Interaction","text":"<p>[January, 2023] NOPA: Neurally-guided Online Probabilistic Assistance for Building Socially Intelligent Home Assistants, Puig et al.,  ICRA </p> <p>[Januaray, 2021] WATCH-AND-HELP: A CHALLENGE FOR SOCIAL PERCEPTION AND HUMAN-AI COLLABORATION, Puig et al., ICLR</p> <p>[October, 2019] On the utility of learning about humans for human-ai coordination, Carroll et al., Neurips</p> <p>[May, 2021] Interaction Flexibility in Artificial Agents Teaming with Human, Nalepka et al., Proceedings of the Annual Meeting of the Cognitive Science Society</p> <p>[December, 2023] LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination, Liu et al., arxiv </p> <p>[May, 2023] Adaptive coordination in social embodied rearrangement, Szot et al., ICML</p> <p>[April, 2023] Generative Agents: Interactive Simulacra of Human Behavior, Park et al., UIST</p>"},{"location":"#human-robot-interaction","title":"Human Robot Interaction","text":""},{"location":"#human-human-interaction","title":"Human-Human Interaction","text":""},{"location":"#challenges","title":"Challenges","text":""},{"location":"#theory-of-mind","title":"Theory of Mind","text":""},{"location":"#social-learning","title":"Social Learning","text":""},{"location":"#simultaneous-interaction","title":"Simultaneous Interaction","text":""},{"location":"#applications","title":"Applications","text":""},{"location":"#health","title":"Health","text":"<p>[March, 2024] Polaris: A Safety-focused LLM Constellation Architecture for Healthcare, Subhabrata Mukherjee et al., arXiv</p> <p>[January, 2024] Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias, Yu He Ke et al., arXiv</p> <p>[February, 2024] Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset, Hengguan Huang et al., arXiv</p> <p>[February, 2024] AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis, Zhihao Fan et al., arXiv</p> <p>[February, 2024] COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt, Suyeon Lee et al., arXiv</p> <p>[May, 2023] Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback, Shang-Ling Hsu et al., arXiv</p> <p>[May, 2023] Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media, Wei Qin et al., arXiv</p> <p>[May, 2023] An artificial intelligence-based chatbot for prostate cancer education: Design and patient evaluation study, Magdalena G\u00f6rtz et al., Digital Health</p> <p>[October, 2024] Conversational Health Agents: A Personalized LLM-Powered Agent Framework, Mahyar Abbasian et al., arXiv</p>"},{"location":"#policy","title":"Policy","text":"<p>[August, 2022] Social Simulacra: Creating Populated Prototypes for Social Computing Systems, Joon Sung Park et al., Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</p> <p>[November, 2024] Do LLMs exhibit human-like response biases? A case study in survey design, Lindia Tjuatja et al., arXiv</p> <p>[February, 2024] Large language models cannot replace human participants because they cannot portray identity groups, Angelina Wang et al., arXiv</p> <p>[February, 2024] Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation, Xinyi Mou et al., arXiv</p> <p>[March, 2024] From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News, Yuhan Liu et al., arXiv                </p>"},{"location":"#education","title":"Education","text":""},{"location":"#concerns","title":"Concerns","text":""},{"location":"#risks","title":"Risks","text":""},{"location":"#safety","title":"Safety","text":""},{"location":"contribution/","title":"Contribution","text":"<p>Hi everyone! Thanks for the help!! Your expertise is invaluable to the community \ud83d\udca1. Here are some steps to contribute to the repository:</p>"},{"location":"contribution/#steps","title":"Steps","text":"<ol> <li>Fork the repository.</li> <li>Add each paper to the <code>main.bib</code> file, under the section you are working on. You could pick one section that fits the paper the most. This file will sync with the Overleaf project <code>main.bib</code> file after your PR is merged. Don't add the papers that are already in the <code>main.bib</code>.</li> <li>Add four new fields for each paper you added: <code>environments</code>, <code>agents</code>, <code>evaluation</code>, and <code>other</code>. The acceptable tags for these four fields are in taxonomy.</li> <li> <p>Update the <code>./docs/paper_table.md</code> file:</p> <ul> <li>Run <code>python bibtex_to_table.py</code> to update the <code>./docs/paper_table.md</code> file.</li> <li>Double-check the output Markdown file and ensure the table is updated correctly.</li> </ul> </li> <li> <p>Update the <code>./docs/README.md</code> file with the paper entry:</p> <ul> <li>Copy and paste the content from the <code>helper</code> column of the <code>./docs/helper.md</code> file to the corresponding section(s) in the <code>./docs/README.md</code> file.</li> <li>Note: If the paper fits multiple sections, you can paste the entry into multiple sections in the <code>./docs/README.md</code> file.</li> </ul> </li> <li> <p>Create a Pull Request:</p> <ul> <li>Once you've completed the above steps, create a pull request to the main repository.</li> <li>Congratulations! \ud83c\udf89</li> </ul> </li> </ol>"},{"location":"contribution/#notes","title":"Notes","text":"<ul> <li>If you have any questions, feel free to ask in the Slack channel or create an issue in the repository.</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>Social Agent Examples:</p> Examples Social agent Socially intelligent agent Agent outputing only yes or no \u2714, if the yes or no is somewhat meaningful \u2714, if the yes or no is interpretable by a certain group of people. But the communication bandwidth is quite limited, so its social intelligence level could be low. Agent outputting only yes \u274c, the agent could not perceive environment and act accordingly \u274c StarCraft Agents \u2714, they interact \u274c, humans cannot understand their internal signals Agents speak an artificial code language that only few people understand \u2714, they interact \u2714, they interact and communicate in a human-interpretable way Trisolarans \u2714, they interact \u274c, their way of interaction is different from how humans communicate. They are essentially mind readers, and they don't need theory of mind A newspaper, or a bot that only responds you with today's weather in Pittsburgh \u274c, it doesn't interact \u274c A Webareana agent \u274c, it only interacts with the browser environment \u274c A tree \u274c, it doesn't interact \u274c A lightbulb with motion sensor that turns on when you walk by ? ? Self-driving cars on the real road \u2714, they interact ?"},{"location":"helper/","title":"Helper","text":"<p>[July, 2023] Communicative Agents for Software Development, Chen Qian et al., arXiv</p>"},{"location":"helper/#environmentslanguage","title":"environments/language","text":"<p>[April, 2024] Autonomous Evaluation and Refinement of Digital Agents, Jiayi Pan et al., arXiv preprint arXiv:2404.06474</p> <p>[April, 2024] Scaling Instructable Agents Across Many Simulated Worlds, SIMA Team et al., arXiv preprint arXiv:2404.10179</p> <p>[March, 2024] Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference, Wei-Lin Chiang et al., arXiv preprint arXiv:2403.04132</p> <p>[March, 2024] Evaluate LLMs in real time with Street Fighter III, OpenGenerativeAI team et al., n/a</p> <p>[December, 2023] Large language models play starcraft ii: Benchmarks and a chain of summarization approach, Weiyu Ma et al., arXiv preprint arXiv:2312.11865</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p> <p>[August, 2023] {CALYPSO}: {LLMs} as Dungeon Masters' Assistants, Andrew Zhu et al., The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)</p> <p>[July, 2023] {I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons, Zhou et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p> <p>[July, 2023] {FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information, Zhu et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p> <p>[March, 2023] Fast Multi-Agent Gridworld Environments for Gymnasium, Ini Oguntola et al., GitHub</p> <p>[December, 2022] Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence, Callison-Burch et al., Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</p> <p>[November, 2022] Human-level play in the game of Diplomacy by combining language models with strategic reasoning, Meta Fundamental AI Research Diplomacy Team (FAIR)\u2020 et al., Science</p> <p>[November, 2022] Introducing ChatGPT, OpenAI et al., n/a</p> <p>[August, 2022] Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage, Kurt Shuster et al., arXiv preprint arXiv:2208.03188</p> <p>[May, 2022] Opt: Open pre-trained transformer language models, Susan Zhang et al., arXiv preprint arXiv:2205.01068</p> <p>[July, 2020] It Takes Two to Lie: One to Lie, and One to Listen, Peskov et al., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</p> <p>[March, 2020] The Hanabi challenge: A new frontier for AI research, Nolan Bard et al., Artificial Intelligence</p> <p>[March, 2020] The Design and Implementation of {X}iao{I}ce, an Empathetic Social Chatbot, Zhou et al., Computational Linguistics</p> <p>[August, 2019] {OpenSpiel}: A Framework for Reinforcement Learning in Games, Marc Lanctot et al., CoRR</p> <p>[July, 2019] Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good, Wang et al., Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</p> <p>[July, 2019] RLCard: A Toolkit for Reinforcement Learning in Card Games, Daochen Zha et al., arXiv preprint arXiv:1910.04376</p> <p>[April, 2019] Wizard of Wikipedia: Knowledge-Powered Conversational Agents, Emily Dinan et al., International Conference on Learning Representations</p> <p>[October, 2018] Decoupling Strategy and Generation in Negotiation Dialogues, He et al., Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</p> <p>[April, 2018] A knowledge-grounded neural conversation model, Marjan Ghazvininejad et al., Proceedings of the AAAI Conference on Artificial Intelligence</p> <p>[March, 2018] Towards empathetic human-robot interactions, Pascale Fung et al., Computational Linguistics and Intelligent Text Processing: 17th International Conference, CICLing 2016, Konya, Turkey, April 3--9, 2016, Revised Selected Papers, Part II 17</p> <p>[September, 2017] Deal or No Deal? End-to-End Learning of Negotiation Dialogues, Lewis et al., Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</p> <p>[August, 2016] A persona-based neural conversation model, Jiwei Li et al., arXiv preprint arXiv:1603.06155</p> <p>[November, 2009] The anatomy of ALICE, Richard S Wallace et al., n/a</p> <p>[January, 2006] Empathic computing, Yang Cai et al., Ambient intelligence in everyday life: Foreword by Emile Aarts</p> <p>[January, 1966] ELIZA\u2014a computer program for the study of natural language communication between man and machine, Joseph Weizenbaum et al., Commun. ACM</p>"},{"location":"helper/#environmentsvirtual","title":"environments/virtual","text":"<p>[October, 2024] Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots, Xavier Puig et al., The Twelfth International Conference on Learning Representations</p> <p>[September, 2020] SEAN: Social Environment for Autonomous Navigation, Nathan Tsoi et al., Proceedings of the 8th International Conference on Human-Agent Interaction</p>"},{"location":"helper/#environmentsrobotics","title":"environments/robotics","text":"<p>[March, 2024] Yell At Your Robot: Improving On-the-Fly from Language Corrections, Lucy Xiaoyang Shi et al., arXiv</p> <p>[December, 2023] RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments, Haoyu Xiong et al., Proceedings of The 6th Conference on Robot Learning</p> <p>[August, 2023] Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration, Chen Wang et al., arXiv</p> <p>[July, 2023] Robotic vision for human-robot interaction and collaboration: A survey and systematic review, Nicole Robinson et al., ACM Transactions on Human-Robot Interaction</p> <p>[June, 2023] One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments, Yufei Wang et al., Robotics: Science and Systems (RSS)</p> <p>[April, 2023] 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction, Katie Winkle et al., J. Hum.-Robot Interact.</p> <p>[March, 2023] Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective, Jacqueline Urakami et al., J. Hum.-Robot Interact.</p> <p>[October, 2022] A survey of multi-agent Human--Robot Interaction systems, Abhinav Dahiya et al., Robotics and Autonomous Systems</p> <p>[August, 2022] Do As I Can and Not As I Say: Grounding Language in Robotic Affordances, Michael Ahn et al., arXiv preprint arXiv:2204.01691</p> <p>[June, 2022] Inner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang et al., arXiv preprint arXiv:2207.05608</p> <p>[June, 2021] A taxonomy to structure and analyze human--robot interaction, Linda Onnasch et al., International Journal of Social Robotics</p> <p>[April, 2016] Human--robot interaction: status and challenges, Thomas B Sheridan et al., Human factors</p>"},{"location":"helper/#modelingin-context-learning","title":"modeling/in-context-learning","text":"<p>[September, 2024] LASER: LLM Agent with State-Space Exploration for Web Navigation, Kaixin Ma et al., arXiv</p> <p>[January, 2024] Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control, Longtao Zheng et al., The Twelfth International Conference on Learning Representations</p> <p>[November, 2023] AdaPlanner: Adaptive Planning from Feedback with Language Models, Haotian Sun et al., Thirty-seventh Conference on Neural Information Processing Systems</p> <p>[May, 2023] Voyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang et al., arXiv</p> <p>[May, 2023] Hierarchical Prompting Assists Large Language Model on Web Navigation, Abishek Sridhar et al., arXiv</p> <p>[May, 2023] SPRING: Studying the Paper and Reasoning to Play Games, Yue Wu et al., arXiv</p> <p>[March, 2023] Language Models can Solve Computer Tasks, Geunwoo Kim et al., arXiv</p> <p>[March, 2023] DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents, Varun Nair et al., arXiv</p>"},{"location":"helper/#modelingfinetuning","title":"modeling/finetuning","text":"<p>[February, 2024] Dual-View Visual Contextualization for Web Navigation, Jihyung Kil et al., arXiv</p> <p>[January, 2024] A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis, Izzeddin Gur et al., The Twelfth International Conference on Learning Representations</p> <p>[January, 2024] GPT-4V(ision) is a Generalist Web Agent, if Grounded, Boyuan Zheng et al., arXiv</p> <p>[November, 2023] From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces, Peter Shaw et al., Thirty-seventh Conference on Neural Information Processing Systems</p> <p>[October, 2023] Understanding HTML with Large Language Models, Izzeddin Gur et al., arXiv</p> <p>[October, 2023] ReAct: Synergizing Reasoning and Acting in Language Models, Shunyu Yao et al., arXiv</p> <p>[May, 2023] Instruction-Finetuned Foundation Models for Multimodal Web Navigation, Hiroki Furuta et al., ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models</p>"},{"location":"helper/#modelingreinforcement-learning","title":"modeling/reinforcement-learning","text":"<p>[March, 2024] SOTOPIA-$\\pi$: Interactive Learning of Socially Intelligent Language Agents, Ruiyi Wang et al., arXiv</p> <p>[March, 2024] TacticAI: an AI assistant for football tactics, Zhe Wang et al., Nature Communications</p> <p>[March, 2023] Computational Language Acquisition with Theory of Mind, Andy Liu et al., arXiv</p> <p>[July, 2022] Language Learning from Communicative Goals and Linguistic Input, Hao Zhu et al., Proceedings of the Annual Meeting of the Cognitive Science Society</p> <p>[April, 2022] Language games meet multi-agent reinforcement learning: A case study for the naming game, Paul Van Eecke et al., Journal of Language Evolution</p> <p>[November, 2019] {EGG}: a toolkit for research on Emergence of lan{G}uage in Games, Kharitonov et al., Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</p> <p>[October, 2018] Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising, Junqi Jin et al., Proceedings of the 27th ACM International Conference on Information and Knowledge Management</p> <p>[February, 2018] Emergent Communication through Negotiation, Kris Cao et al., International Conference on Learning Representations</p> <p>[April, 2017] Mastering the game of go without human knowledge, David Silver et al., nature</p> <p>[January, 2016] Mastering the game of Go with deep neural networks and tree search, David Silver et al., nature</p>"},{"location":"helper/#evaluationlanguage","title":"evaluation/language","text":"<p>[October, 2024] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[March, 2024] RoleInteract: Evaluating the Social Interaction of Role-Playing Agents, Hongzhan Chen et al., arXiv</p> <p>[March, 2024] How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments, Jen-tse Huang et al., arXiv</p> <p>[February, 2024] Automatic Evaluation for Mental Health Counseling using LLMs, Anqi Li et al., arXiv</p> <p>[February, 2024] How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis, Federico Bianchi et al., arXiv</p> <p>[February, 2024] Can Large Language Model Agents Simulate Human Trust Behaviors?, Chengxing Xie et al., ArXiv</p> <p>[January, 2024] LLM Harmony: Multi-Agent Communication for Problem Solving, Sumedh Rasal et al., ArXiv</p> <p>[December, 2023] CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society, Guohao Li et al., Advances in Neural Information Processing Systems</p> <p>[October, 2023] Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay, Yihuai Lan et al., arXiv preprint arXiv:2310.14985</p> <p>[October, 2023] AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems, Junjie Zhang et al., arXiv</p> <p>[September, 2023] Approximating Online Human Evaluation of Social Chatbots with Prompting, Svikhnushina et al., Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p> <p>[August, 2023] CharacterChat: Learning towards Conversational AI with Personalized Social Support, Quan Tu et al., arXiv</p> <p>[August, 2023] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate, Chi-Min Chan et al., arXiv</p> <p>[May, 2023] PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits, Hang Jiang et al., NAACL Findings</p> <p>[May, 2023] Psychological Metrics for Dialog System Evaluation, Salvatore Giorgi et al., arXiv</p> <p>[May, 2023] ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems, Sarik Ghazarian et al., arXiv</p> <p>[November, 2021] A Comprehensive Assessment of Dialog Evaluation Metrics, Yeh et al., The First Workshop on Evaluations and Assessments of Neural Conversation Systems</p> <p>[November, 2020] {GRADE}: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems, Huang et al., Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</p> <p>[July, 2020] {C}onvo{K}it: A Toolkit for the Analysis of Conversations, Chang et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p> <p>[July, 2020] Unsupervised Evaluation of Interactive Dialog with {D}ialo{GPT}, Mehri et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>"},{"location":"helper/#evaluationembodied","title":"evaluation/embodied","text":"<p>[December, 2024] How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning, Siddarth Singh et al., arXiv</p> <p>[March, 2024] Embodied LLM Agents Learn to Cooperate in Organized Teams, Xudong Guo et al., arXiv</p> <p>[December, 2022] Don{'}t Copy the Teacher: Data and Model Challenges in Embodied Dialogue, Min et al., Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</p> <p>[September, 2022] {Dialog Acts for Task-Driven Embodied Agents}, Spandana Gella et al., Proceedings of the 23nd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDial)</p> <p>[June, 2022] Analysis of Dialogue in Human-Human Collaboration in {M}inecraft, Ichikawa et al., Proceedings of the Thirteenth Language Resources and Evaluation Conference</p> <p>[February, 2022] {TEACh: Task-driven Embodied Agents that Chat}, Aishwarya Padmakumar et al., Proceedings of the AAAI Conference on Artificial Intelligence</p> <p>[November, 2021] {M}ind{C}raft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks, Bara et al., Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</p> <p>[July, 2021] Scalable evaluation of multi-agent reinforcement learning with melting pot, Joel Z Leibo et al., International conference on machine learning</p> <p>[January, 2021] Evaluating the Robustness of Collaborative Agents, Paul Knott et al., Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems</p> <p>[November, 2020] A Cordial Sync: Going Beyond Marginal Policies For Multi-Agent Embodied Tasks, Unnat Jain et al., ECCV</p> <p>[July, 2019] Collaborative Dialogue in {M}inecraft, Narayan-Chen et al., Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</p> <p>[June, 2019] Two Body Problem: Collaborative Visual Task Completion, Unnat Jain et al., CVPR</p> <p>[May, 2016] Evaluation of starcraft artificial intelligence competition bots by experienced human players, Man-Je Kim et al., Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems</p>"},{"location":"helper/#evaluationrobotics","title":"evaluation/robotics","text":"<p>[March, 2024] HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation, Carmelo Sferrazza et al., arXiv</p> <p>[December, 2020] Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition, Y. Mizuchi et al., Advanced Robotics</p> <p>[July, 2020] Safety bounds in human robot interaction: A survey, Angeliki Zacharaki et al., Safety science</p> <p>[December, 2015] RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots, Luca Iocchi et al., Artificial Intelligence</p> <p>[October, 2011] A meta-analysis of factors affecting trust in human-robot interaction, Peter A Hancock et al., Human factors</p> <p>[November, 2009] Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots, Christoph Bartneck et al., International journal of social robotics</p> <p>[March, 2006] Common metrics for human-robot interaction, Aaron Steinfeld et al., Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction</p> <p>[January, 2003] Theory and evaluation of human robot interactions, J. Scholtz et al., 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the</p>"},{"location":"helper/#interactionstext","title":"interactions/text","text":"<p>[May, 2024] \" It's the only thing I can trust\": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance, JiWoong Jang et al., arXiv preprint arXiv:2403.03297</p> <p>[March, 2024] AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy, Daniel Pillis et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p> <p>[March, 2024] Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration, Crystal Qian et al., Proceedings of the 29th International Conference on Intelligent User Interfaces</p> <p>[May, 2023] The Effects of Engaging and Affective Behaviors of Virtual Agents in Group Decision-Making, Hanseob Kim et al., Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</p> <p>[April, 2023] Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions, Amon Rapp et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p> <p>[April, 2023] Exploring effects of chatbot-based social contact on reducing mental illness stigma, Yi-Chieh Lee et al., Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</p> <p>[September, 2022] Interacting with a chatbot-based advising system: Understanding the effect of chatbot personality and user gender on behavior, Mohammad Amin Kuhail et al., Informatics</p> <p>[April, 2022] User perceptions of extraversion in chatbots after repeated use, Sarah Theres V{\\\"o}lkel et al., Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</p>"},{"location":"helper/#interactionsembodied","title":"interactions/embodied","text":"<p>[December, 2023] Llm-powered hierarchical language agent for real-time human-ai coordination, Jijia Liu et al., arXiv preprint arXiv:2312.15224</p> <p>[May, 2023] Adaptive coordination in social embodied rearrangement, Andrew Szot et al., International Conference on Machine Learning</p> <p>[April, 2023] Generative agents: Interactive simulacra of human behavior, Joon Sung Park et al., Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</p> <p>[January, 2023] Nopa: Neurally-guided online probabilistic assistance for building socially intelligent home assistants, Xavier Puig et al., 2023 IEEE International Conference on Robotics and Automation (ICRA)</p> <p>[May, 2021] Interaction flexibility in artificial agents teaming with humans, Patrick Nalepka et al., Proceedings of the Annual Meeting of the Cognitive Science Society</p> <p>[January, 2021] Watch-And-Help: A Challenge for Social Perception and Human-{{}AI{}} Collaboration, Xavier Puig et al., International Conference on Learning Representations</p> <p>[October, 2019] On the utility of learning about humans for human-ai coordination, Micah Carroll et al., Advances in neural information processing systems</p>"},{"location":"helper/#applicationshealth","title":"applications/health","text":"<p>[October, 2024] Conversational Health Agents: A Personalized LLM-Powered Agent Framework, Mahyar Abbasian et al., arXiv</p> <p>[March, 2024] Polaris: A Safety-focused LLM Constellation Architecture for Healthcare, Subhabrata Mukherjee et al., arXiv</p> <p>[February, 2024] Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset, Hengguan Huang et al., arXiv</p> <p>[February, 2024] AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis, Zhihao Fan et al., arXiv</p> <p>[February, 2024] COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt, Suyeon Lee et al., arXiv</p> <p>[January, 2024] Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias, Yu He Ke et al., arXiv</p> <p>[May, 2023] Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback, Shang-Ling Hsu et al., arXiv</p> <p>[May, 2023] Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media, Wei Qin et al., arXiv</p> <p>[May, 2023] An artificial intelligence-based chatbot for prostate cancer education: Design and patient evaluation study, Magdalena G\u00f6rtz et al., Digital Health</p>"},{"location":"helper/#applicationspolicy","title":"applications/policy","text":"<p>[November, 2024] Do LLMs exhibit human-like response biases? A case study in survey design, Lindia Tjuatja et al., arXiv</p> <p>[March, 2024] From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News, Yuhan Liu et al., arXiv</p> <p>[February, 2024] Large language models cannot replace human participants because they cannot portray identity groups, Angelina Wang et al., arXiv</p> <p>[February, 2024] Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation, Xinyi Mou et al., arXiv</p> <p>[August, 2022] Social Simulacra: Creating Populated Prototypes for Social Computing Systems, Joon Sung Park et al., Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</p>"},{"location":"paper_table/","title":"Paper table","text":"Title Date environments agents evaluation other Communicative Agents for Software Development July, 2023 collaboration, embodied prompting_and_in_context_learning, more_than_three_agents rule_based n/a Autonomous Evaluation and Refinement of Digital Agents April, 2024 virtual prompting_and_in_context_learning, finetuning qualitative human_agent Scaling Instructable Agents Across Many Simulated Worlds April, 2024 embodied prompting_and_in_context_learning, finetuning qualitative human_agent Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference March, 2024 text, mixed_objectives prompting_and_in_context_learning qualitative, human human_agent Evaluate LLMs in real time with Street Fighter III March, 2024 embodied prompting_and_in_context_learning qualitative human_agent Large language models play starcraft ii: Benchmarks and a chain of summarization approach December, 2023 embodied prompting_and_in_context_learning, finetuning qualitative human_agent CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents October, 2023 competition, text prompting_and_in_context_learning, two_agents rule_based n/a {CALYPSO}: {LLMs} as Dungeon Masters' Assistants August, 2023 text, implicit_objectives more_than_three_agents, finetuning human human_agent {I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons July, 2023 text, implicit_objectives more_than_three_agents, reinforcement_learning human, rule_based human_agent {FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information July, 2023 text, implicit_objectives more_than_three_agents, finetuning human, rule_based human_agent Fast Multi-Agent Gridworld Environments for Gymnasium March, 2023 collaboration, competition, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence December, 2022 text, implicit_objectives more_than_three_agents, pretraining, finetuning human, rule_based human_agent Human-level play in the game of Diplomacy by combining language models with strategic reasoning November, 2022 competition, text more_than_three_agents, reinforcement_learning, finetuning rule_based human_agent Introducing ChatGPT November, 2022 text, mixed_objectives prompting_and_in_context_learning, agents_with_memory qualitative, human human_agent Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage August, 2022 text, mixed_objectives finetuning qualitative, human n/a Opt: Open pre-trained transformer language models May, 2022 text, mixed_objectives finetuning, agents_with_personas qualitative, human human_agent It Takes Two to Lie: One to Lie, and One to Listen July, 2020 text, mixed_objectives more_than_three_agents model_based human_agent The Hanabi challenge: A new frontier for AI research March, 2020 collaboration, text more_than_three_agents rule_based n/a The Design and Implementation of {X}iao{I}ce, an Empathetic Social Chatbot March, 2020 text, mixed_objectives finetuning, agents_with_personas qualitative, human human_agent {OpenSpiel}: A Framework for Reinforcement Learning in Games August, 2019 collaboration, competition, mixed_objectives, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good July, 2019 text, mixed_objectives two_agents, finetuning human, rule_based human_agent RLCard: A Toolkit for Reinforcement Learning in Card Games July, 2019 collaboration, competition, mixed_objectives, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a Wizard of Wikipedia: Knowledge-Powered Conversational Agents April, 2019 text, mixed_objectives, implicit_objectives finetuning, agents_with_personas qualitative, human human_agent Decoupling Strategy and Generation in Negotiation Dialogues October, 2018 text, mixed_objectives finetuning, reinforcement_learning, two_agents, agents_with_memory human n/a A knowledge-grounded neural conversation model April, 2018 text, mixed_objectives, implicit_objectives finetuning qualitative, human human_agent Towards empathetic human-robot interactions March, 2018 text, mixed_objectives agents_with_personas qualitative, human human_agent Deal or No Deal? End-to-End Learning of Negotiation Dialogues September, 2017 text, mixed_objectives reinforcement_learning, two_agents, agents_with_memory rule_based human_agent A persona-based neural conversation model August, 2016 text, mixed_objectives finetuning, agents_with_personas qualitative, human human_agent The anatomy of ALICE November, 2009 text, mixed_objectives agents_with_personas human n/a Empathic computing January, 2006 text, mixed_objectives agents_with_personas human n/a ELIZA\u2014a computer program for the study of natural language communication between man and machine January, 1966 text, mixed_objectives agents_with_personas human n/a Habitat 3.0: A Co-Habitat for Humans, Avatars, and Robots October, 2024 mixed_objectives, embodied reinforcement_learning rule_based human_agent, simulated_humans SEAN: Social Environment for Autonomous Navigation September, 2020 mixed_objectives, embodied reinforcement_learning rule_based human_agent, simulated_humans Yell At Your Robot: Improving On-the-Fly from Language Corrections March, 2024 collaboration, mixed_objectives, robotics two_agents, finetuning, reinforcement_learning, agents_with_memory human human_agent RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments December, 2023 implicit_objectives, robotics reinforcement_learning, agents_with_memory human, rule_based simulated_humans Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration August, 2023 collaboration, mixed_objectives, robotics two_agents, reinforcement_learning human human_agent, simulated_humans Robotic vision for human-robot interaction and collaboration: A survey and systematic review July, 2023 collaboration, mixed_objectives, implicit_objectives, robotics two_agents, agent_teams, agents_with_personas human, rule_based human_agent, simulated_humans One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments June, 2023 robotics reinforcement_learning human, rule_based human_agent 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction April, 2023 robotics two_agents human human_agent Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective March, 2023 collaboration, mixed_objectives, implicit_objectives, robotics two_agents human human_agent A survey of multi-agent Human--Robot Interaction systems October, 2022 collaboration, mixed_objectives, robotics two_agents, more_than_three_agents, agent_teams human human_agent Do As I Can and Not As I Say: Grounding Language in Robotic Affordances August, 2022 mixed_objectives, implicit_objectives, robotics finetuning, reinforcement_learning, agents_with_memory human, rule_based, model_based simulated_humans Inner Monologue: Embodied Reasoning through Planning with Language Models June, 2022 mixed_objectives, implicit_objectives, robotics finetuning, reinforcement_learning, agents_with_memory human, rule_based, model_based simulated_humans A taxonomy to structure and analyze human--robot interaction June, 2021 collaboration, mixed_objectives, robotics two_agents human human_agent Human--robot interaction: status and challenges April, 2016 collaboration, mixed_objectives, robotics two_agents, finetuning, reinforcement_learning human human_agent LASER: LLM Agent with State-Space Exploration for Web Navigation September, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans AdaPlanner: Adaptive Planning from Feedback with Language Models November, 2023 mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Voyager: An Open-Ended Embodied Agent with Large Language Models May, 2023 mixed_objectives, implicit_objectives, embodied prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Hierarchical Prompting Assists Large Language Model on Web Navigation May, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans SPRING: Studying the Paper and Reasoning to Play Games May, 2023 mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Language Models can Solve Computer Tasks March, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning rule_based simulated_humans DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents March, 2023 collaboration, mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agent_teams, agents_with_memory rule_based simulated_humans Dual-View Visual Contextualization for Web Navigation February, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans GPT-4V(ision) is a Generalist Web Agent, if Grounded January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces November, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans Understanding HTML with Large Language Models October, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning rule_based simulated_humans ReAct: Synergizing Reasoning and Acting in Language Models October, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans Instruction-Finetuned Foundation Models for Multimodal Web Navigation May, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans SOTOPIA-$\\pi$: Interactive Learning of Socially Intelligent Language Agents March, 2024 collaboration, competition, mixed_objectives, text reinforcement_learning, two_agents rule_based, human, model_based simulated_humans TacticAI: an AI assistant for football tactics March, 2024 virtual, collaboration, competition, mixed_objectives reinforcement_learning, agent_teams rule_based n/a Computational Language Acquisition with Theory of Mind March, 2023 collaboration, virtual reinforcement_learning, two_agents rule_based simulated_humans Language Learning from Communicative Goals and Linguistic Input July, 2022 collaboration, virtual reinforcement_learning, two_agents rule_based simulated_humans Language games meet multi-agent reinforcement learning: A case study for the naming game April, 2022 collaboration, competition, mixed_objectives reinforcement_learning, two_agents rule_based n/a {EGG}: a toolkit for research on Emergence of lan{G}uage in Games November, 2019 collaboration, text reinforcement_learning, two_agents rule_based n/a Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising October, 2018 competition, virtual reinforcement_learning, more_than_three_agents rule_based n/a Emergent Communication through Negotiation February, 2018 mixed_objectives, text reinforcement_learning, two_agents rule_based n/a Mastering the game of go without human knowledge April, 2017 competition, virtual reinforcement_learning rule_based human_agent Mastering the game of Go with deep neural networks and tree search January, 2016 competition, virtual reinforcement_learning rule_based human_agent SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents October, 2024 mixed_objectives, text prompting_and_in_context_learning, two_agents model_based, human human_agent RoleInteract: Evaluating the Social Interaction of Role-Playing Agents March, 2024 implicit_objectives, text prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas rule_based simulated_humans How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments March, 2024 mixed_objectives, text prompting_and_in_context_learning, more_than_three_agents rule_based more_omniscient Automatic Evaluation for Mental Health Counseling using LLMs February, 2024 collaboration, text prompting_and_in_context_learning, two_agents model_based n/a How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis February, 2024 mixed_objectives, text prompting_and_in_context_learning, two_agents rule_based more_information_asymmetrical Can Large Language Model Agents Simulate Human Trust Behaviors? February, 2024 text prompting_and_in_context_learning human, model_based n/a LLM Harmony: Multi-Agent Communication for Problem Solving January, 2024 text prompting_and_in_context_learning human, model_based n/a CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society December, 2023 mixed_objectives, text prompting_and_in_context_learning, agent_teams human, model_based human_agent Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay October, 2023 mixed_objectives, text prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas model_based, rule_based simulated_humans AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems October, 2023 mixed_objectives, text prompting_and_in_context_learning, more_than_three_agents, agents_with_memory, agents_with_personas rule_based simulated_humans Approximating Online Human Evaluation of Social Chatbots with Prompting September, 2023 mixed_objectives, text prompting_and_in_context_learning, two_agents model_based n/a CharacterChat: Learning towards Conversational AI with Personalized Social Support August, 2023 implicit_objectives, text prompting_and_in_context_learning, two_agents, agents_with_memory, agents_with_personas model_based, human simulated_humans ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate August, 2023 collaboration, text prompting_and_in_context_learning, more_than_three_agents rule_based n/a PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits May, 2023 text prompting_and_in_context_learning human, model_based n/a Psychological Metrics for Dialog System Evaluation May, 2023 text two_agents human, rule_based human_agent ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems May, 2023 text two_agents human, model_based human_agent A Comprehensive Assessment of Dialog Evaluation Metrics November, 2021 text n/a human, model_based, rule_based n/a {GRADE}: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems November, 2020 text two_agents human, model_based human_agent {C}onvo{K}it: A Toolkit for the Analysis of Conversations July, 2020 text n/a human, model_based, rule_based n/a Unsupervised Evaluation of Interactive Dialog with {D}ialo{GPT} July, 2020 text two_agents human, model_based human_agent How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning December, 2024 collaboration, embodied reinforcement_learning, more_than_three_agents rule_based n/a Embodied LLM Agents Learn to Cooperate in Organized Teams March, 2024 collaboration, embodied prompting_and_in_context_learning, more_than_three_agents model_based, human education Don{'}t Copy the Teacher: Data and Model Challenges in Embodied Dialogue December, 2022 mixed_objectives, collaboration, embodied agents_with_memory qualitative, human, rule_based n/a {Dialog Acts for Task-Driven Embodied Agents} September, 2022 collaboration, embodied finetuning, two_agents rule_based human_agent Analysis of Dialogue in Human-Human Collaboration in {M}inecraft June, 2022 collaboration, embodied two_agents human, rule_based human_agent {TEACh: Task-driven Embodied Agents that Chat} February, 2022 collaboration, embodied finetuning, two_agents rule_based human_agent {M}ind{C}raft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks November, 2021 collaboration, embodied finetuning, two_agents human, rule_based human_agent Scalable evaluation of multi-agent reinforcement learning with melting pot July, 2021 collaboration, competition, mixed_objectives, embodied reinforcement_learning, more_than_three_agents rule_based n/a Evaluating the Robustness of Collaborative Agents January, 2021 collaboration, embodied reinforcement_learning rule_based n/a A Cordial Sync: Going Beyond Marginal Policies For Multi-Agent Embodied Tasks November, 2020 collaboration, embodied finetuning, reinforcement_learning, two_agents rule_based n/a Collaborative Dialogue in {M}inecraft July, 2019 collaboration, embodied two_agents human, rule_based human_agent Two Body Problem: Collaborative Visual Task Completion June, 2019 collaboration, embodied finetuning, reinforcement_learning, two_agents rule_based n/a Evaluation of starcraft artificial intelligence competition bots by experienced human players May, 2016 collaboration, competition, mixed_objectives, embodied more_than_three_agents human, rule_based human_agent HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation March, 2024 collaboration, mixed_objectives, robotics reinforcement_learning human, model_based human_agent, simulated_humans Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition December, 2020 competition, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Safety bounds in human robot interaction: A survey July, 2020 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots December, 2015 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent A meta-analysis of factors affecting trust in human-robot interaction October, 2011 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots November, 2009 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Common metrics for human-robot interaction March, 2006 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based, model_based human_agent Theory and evaluation of human robot interactions January, 2003 collaboration, mixed_objectives, robotics reinforcement_learning human human_agent \" It's the only thing I can trust\": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance May, 2024 text prompting_and_in_context_learning qualitative, human human_agent AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy March, 2024 text prompting_and_in_context_learning qualitative human_agent Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration March, 2024 text prompting_and_in_context_learning human, qualitative human_agent The Effects of Engaging and Affective Behaviors of Virtual Agents in Group Decision-Making May, 2023 embodied n/a human human_agent Collaborating with a Text-Based Chatbot: An Exploration of Real-World Collaboration Strategies Enacted during Human-Chatbot Interactions April, 2023 text prompting_and_in_context_learning qualitative human_agent Exploring effects of chatbot-based social contact on reducing mental illness stigma April, 2023 text prompting_and_in_context_learning qualitative, human human_agent, health Interacting with a chatbot-based advising system: Understanding the effect of chatbot personality and user gender on behavior September, 2022 text n/a qualitative, human human_agent, education User perceptions of extraversion in chatbots after repeated use April, 2022 text n/a human human_agent Llm-powered hierarchical language agent for real-time human-ai coordination December, 2023 collaboration, embodied reinforcement_learning rule_based n/a Adaptive coordination in social embodied rearrangement May, 2023 collaboration, embodied prompting_and_in_context_learning rule_based n/a Generative agents: Interactive simulacra of human behavior April, 2023 mixed_objectives, embodied prompting_and_in_context_learning rule_based n/a Nopa: Neurally-guided online probabilistic assistance for building socially intelligent home assistants January, 2023 collaboration, embodied reinforcement_learning rule_based n/a Interaction flexibility in artificial agents teaming with humans May, 2021 collaboration, embodied reinforcement_learning rule_based n/a Watch-And-Help: A Challenge for Social Perception and Human-{{}AI{}} Collaboration January, 2021 collaboration, embodied reinforcement_learning rule_based n/a On the utility of learning about humans for human-ai coordination October, 2019 collaboration, embodied reinforcement_learning rule_based n/a Conversational Health Agents: A Personalized LLM-Powered Agent Framework October, 2024 mixed_objectives, text prompting_and_in_context_learning, more_than_three_agents rule_based human_agent, health Polaris: A Safety-focused LLM Constellation Architecture for Healthcare March, 2024 mixed_objectives, virtual prompting_and_in_context_learning, finetuning, reinforcement_learning, agent_teams human, rule_based human_agent, health Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset February, 2024 mixed_objectives, text prompting_and_in_context_learning, finetuning, agent_teams human, rule_based human_agent, health AI Hospital: Interactive Evaluation and Collaboration of LLMs as Intern Doctors for Clinical Diagnosis February, 2024 collaboration, text prompting_and_in_context_learning, agent_teams, agents_with_personas human simulated_humans, health COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt February, 2024 text prompting_and_in_context_learning, two_agents, agents_with_memory model_based health Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias January, 2024 mixed_objectives, text prompting_and_in_context_learning, agent_teams, agents_with_personas human simulated_humans, health Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice and Feedback May, 2023 text prompting_and_in_context_learning, more_than_three_agents human human_agent, health Read, Diagnose and Chat: Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media May, 2023 mixed_objectives, text prompting_and_in_context_learning, two_agents n/a human_agent, health An artificial intelligence-based chatbot for prostate cancer education: Design and patient evaluation study May, 2023 text finetuning, two_agents qualitative human_agent, health Do LLMs exhibit human-like response biases? A case study in survey design November, 2024 text prompting_and_in_context_learning human, model_based policy From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News March, 2024 text more_than_three_agents model_based policy Large language models cannot replace human participants because they cannot portray identity groups February, 2024 text n/a n/a policy Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation February, 2024 text more_than_three_agents model_based policy Social Simulacra: Creating Populated Prototypes for Social Computing Systems August, 2022 text, implicit_objectives more_than_three_agents human policy"},{"location":"paper_table/#basic-stats","title":"Basic Stats","text":"<p>Total number of papers: 140</p>"},{"location":"paper_table/#subsections","title":"Subsections","text":"<p>environments/language: 30 environments/virtual: 2 environments/robotics: 12 modeling/in-context-learning: 8 modeling/finetuning: 7 modeling/reinforcement-learning: 10 evaluation/language: 20 evaluation/embodied: 13 evaluation/robotics: 8 interactions/text: 8 interactions/embodied: 7 applications/health: 9 applications/policy: 5</p>"},{"location":"taxonomy/","title":"Tags that you can add to each field","text":"<p>We ask you to add four additional fields to each bibtex entry. The format of a bibtex you should add to <code>main.bib</code> is as follows</p> <pre><code>@misc{Nobody37,\n    author = \"Nobody Jr\",\n    title = \"The last missing piece of AGI\",\n    year = \"2037\",\n    url = \"https://pdf.agi.org\",\n    environments = {mixed_objectives, implicit_objectives, robotics},\n    agents = {agent_teams, more_than_three_agents, agents_with_memory, agents_with_personas},\n    evaluation = {model_based},\n    other = {human_involvement}\n}</code></pre>"},{"location":"taxonomy/#1-environments-and-tasks","title":"1 Environments and Tasks","text":"<p>Here are acceptable tags for <code>environments</code> field: <pre><code>collaboration, competition, mixed_objectives, implicit_objectives,\ntext, virtual, embodied, robotics,\nn/a</code></pre> Please find the explanations to each of these tags below:</p>"},{"location":"taxonomy/#social-interaction-types","title":"Social interaction types","text":"<ol> <li>Collaboration (<code>collaboration</code>): The objectives are shared among agents</li> <li>Competition (<code>competition</code>): The objectives are zero-sum</li> <li>Mixed Objectives (<code>mixed_objectives</code>): Agents\u2019 have different goals, but they are not zero-sum</li> <li>Implicit Objectives (<code>implicit_objectives</code>): Goals are not expressed explicitly</li> </ol>"},{"location":"taxonomy/#domains","title":"Domains","text":"<ol> <li>Text (<code>text</code>): non-embodied environments with text-based observation spaces and action spaces, e.g. chatbots environment</li> <li>Virtual (<code>virtual</code>): non-embodied environments with multimodal observation spaces and/or actions spaces, e.g. web browser environment</li> <li>Embodied (<code>embodied</code>): environments where policies interact with the world through the observation and actions of \"bodies\" (which also implies ego-centric view). A body typically takes up space and has the ability to influence the environment, e.g. Minecraft, Habitat, AI2THOR </li> <li>Robotics (<code>robotics</code>): real physical world environment</li> </ol> <p>Embodied environments in principle include robotics environments, but here we consider only the non-real physical world ones as embodied environments. </p> <p><code>n/a</code> means there is no environment in the paper, or the environment is not covered in the above categorization. Please use <code>n/a</code> sparingly.</p>"},{"location":"taxonomy/#2-agents-and-modeling","title":"2 Agents and Modeling","text":"<p>Here are acceptable tags for <code>agents</code> field: <pre><code>prompting_and_in_context_learning, finetuning, reinforcement_learning, pretraining,\ntwo_agents, more_than_three_agents, agent_teams,\nagents_with_memory, agents_with_personas,\nn/a</code></pre> These tags are straight-forward. Please note that we do count humans as agents here. <code>n/a</code> is similar to above. </p>"},{"location":"taxonomy/#3-evaluation","title":"3 Evaluation","text":"<p>Here are acceptable tags for <code>agents</code> field: <pre><code>qualitative, human, rule_based, model_based,\nn/a</code></pre></p> <ol> <li>Only qualitative evaluation (<code>qualitative</code>): You should definitely add this tag if a work is only based on qualitative evaluation</li> <li>Human evaluation (<code>human</code>): Quantitative evaluation based on human judgment</li> <li>Rule-based evaluation (<code>rule_based</code>): The evaluation is based on a set of rules</li> <li>Model-based evaluation (<code>model_based</code>): Using machine learning model to judge</li> </ol>"},{"location":"taxonomy/#4-other","title":"4 Other","text":"<p>Here are acceptable tags for <code>other</code> field: <pre><code>human_agent, simulated_humans, \nhealth, education, policy,\nfully omniscient, more omniscient, more information asymmetrical\nn/a</code></pre></p>"},{"location":"taxonomy/#human-involvement","title":"Human involvement","text":"<p><code>human_agent</code> means at least one of the agent is a human. <code>simulated_humans</code> means the agents are simulated humans.</p>"},{"location":"taxonomy/#application-domains","title":"Application domains","text":"<p><code>health</code> and <code>education</code> are self-explanatory. <code>policy</code> means the simulation is related to policy-making.</p>"},{"location":"taxonomy/#information-asymmetry-levels","title":"Information asymmetry levels","text":"<p><code>fully_omniscient</code> means all agents have full information about the environment and other agents. <code>more_omniscient</code> means agents have only one or two sources of information that other agents do not have (in the prompts for LLM-powered agents). This includes but not limited to roles, output format, occupation, partial overview of the environment, etc. <code>more_information_asymmetrical</code> means agents have various of different information sources that other agents do not have.</p> <p>Here you can use <code>n/a</code> if none of the above tags fits the paper.</p>"}]}